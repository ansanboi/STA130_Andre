{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a29dab0",
   "metadata": {},
   "source": [
    "# STA130 Homework 08\n",
    "\n",
    "Please see the course [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) for the list of topics covered in this homework assignment, and a list of topics that might appear during ChatBot conversations which are \"out of scope\" for the purposes of this homework assignment (and hence can be safely ignored if encountered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eee301",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Introduction</u></summary>\n",
    "\n",
    "### Introduction\n",
    "    \n",
    "A reasonable characterization of STA130 Homework is that it simply defines a weekly reading comprehension assignment. \n",
    "Indeed, STA130 Homework essentially boils down to completing various understanding confirmation exercises oriented around coding and writing tasks.\n",
    "However, rather than reading a textbook, STA130 Homework is based on ChatBots so students can interactively follow up to clarify questions or confusion that they may still have regarding learning objective assignments.\n",
    "\n",
    "> Communication is a fundamental skill underlying statistics and data science, so STA130 Homework based on ChatBots helps practice effective two-way communication as part of a \"realistic\" dialogue activity supporting underlying conceptual understanding building. \n",
    "\n",
    "It will likely become increasingly tempting to rely on ChatBots to \"do the work for you\". But when you find yourself frustrated with a ChatBots inability to give you the results you're looking for, this is a \"hint\" that you've become overreliant on the ChatBots. Your objective should not be to have ChatBots \"do the work for you\", but to use ChatBots to help you build your understanding so you can efficiently leverage ChatBots (and other resources) to help you work more efficiently.<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Instructions</u></summary>\n",
    "\n",
    "### Instructions\n",
    "    \n",
    "1. Code and write all your answers (for both the \"Pre-lecture\" and \"Post-lecture\" HW) in a python notebook (in code and markdown cells) \n",
    "    \n",
    "> It is *suggested but not mandatory* that you complete the \"Pre-lecture\" HW prior to the Monday LEC since (a) all HW is due at the same time; but, (b) completing some of the HW early will mean better readiness for LEC and less of a \"procrastentation cruch\" towards the end of the week...\n",
    "    \n",
    "2. Paste summaries of your ChatBot sessions (including link(s) to chat log histories if you're using ChatGPT) within your notebook\n",
    "    \n",
    "> Create summaries of your ChatBot sessions by using concluding prompts such as \"Please provide a summary of our exchanges here so I can submit them as a record of our interactions as part of a homework assignment\" or, \"Please provide me with the final working verson of the code that we created together\"\n",
    "    \n",
    "3. Save your python jupyter notebook in your own account and \"repo\" on [github.com](github.com) and submit a link to that notebook though Quercus for assignment marking<br><br>\n",
    "\n",
    "</details>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Prompt Engineering?</u></summary>\n",
    "    \n",
    "### Prompt Engineering? \n",
    "    \n",
    "The questions (as copy-pasted prompts) are designed to initialize appropriate ChatBot conversations which can be explored in the manner of an interactive and dynamic textbook; but, it is nonetheless **strongly recommendated** that your rephrase the questions in a way that you find natural to ensure a clear understanding of the question. Given sensible prompts the represent a question well, the two primary challenges observed to arise from ChatBots are \n",
    "\n",
    "1. conversations going beyond the intended scope of the material addressed by the question; and, \n",
    "2. unrecoverable confusion as a result of sequential layers logial inquiry that cannot be resolved. \n",
    "\n",
    "In the case of the former (1), adding constraints specifying the limits of considerations of interest tends to be helpful; whereas, the latter (2) is often the result of initial prompting that leads to poor developments in navigating the material, which are likely just best resolve by a \"hard reset\" with a new initial approach to prompting.  Indeed, this is exactly the behavior [hardcoded into copilot](https://answers.microsoft.com/en-us/bing/forum/all/is-this-even-normal/0b6dcab3-7d6c-4373-8efe-d74158af3c00)...\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc1200",
   "metadata": {},
   "source": [
    "### Marking Rubric (which may award partial credit)\n",
    "- [0.1 points]: All relevant ChatBot summaries [including link(s) to chat log histories if you're using ChatGPT] are reported within the notebook\n",
    "- [0.2 points]: Well-communicated and sensible answers for Question \"2\"\n",
    "- [0.2 points]: Correct code and well-communicated correct answer for Question \"4\" \n",
    "- [0.2 points]: Correct calculations for requested metrics in Question \"6\" \n",
    "- [0.3 points]: Correct and well-communicated explanation of differences for Question \"7\" \n",
    "<!-- - [0.1 points]: Written submission evaluation and enagement confirmation with ChatBot summaries for \"8\", \"10\"-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67686639",
   "metadata": {},
   "source": [
    "## \"Pre-lecture\" HW [*completion prior to next LEC is suggested but not mandatory*]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a53734",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Start a ChatBot session to understand what a *Classification Decision Tree* is: (a) ask the ChatBot to describe the type of problem a *Classification Decision Tree* addresses and provide some examples of real-world applications where this might be particularly useful, and then (b) make sure you understand the difference between how a *Classification Decision Tree* makes *(classification) predictions* versus how *Multiple Linear Regression* makes *(regression) predictions*<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _The first part (a) of this question is looking for you to understand the difference between **classification** and **regression**. The second part (b) of the questions is looking for a fairly high level understanding of the general nature of a decision tree and how it is based on making sequential decisions down the *nodes* of *tree* in order to eventually make a final prediction. This part (b) is essentially the **Classification Decision Tree** analog of \"explain how the **linear form** makes a prediciton in **Multiple Linear Regression** generally speaking\"; namely,\"explain how the **tree** makes a prediciton in a **Classification Decision Tree** generally speaking\"._\n",
    "> \n",
    "> _**If you're struggling with this, it would probably be most helpful to go search for and some images of example decision trees to look at!**_\n",
    "> \n",
    "> - _You may be beginning to realize or will nonetheless eventually come to understand that the sequential decisions at each stage of the **Decision Tree** are **interactions** (in the same manner as **interactions** in **Multiple Linear Regression**.  Once you start to see that and it's making sense to you then you'll increasingly appreciate how **complex** **Decision Tree** models can be, even though they're pretty simple to understand if you just look at one._\n",
    ">\n",
    "> ---\n",
    ">    \n",
    "> _When using chatbots, it's often more effective (and enjoyable) to ask concise, single questions rather than presenting complex, multi-part queries. This approach can help in obtaining clearer and more specific responses (that might be more enjoyable to interact with). You can always ask multi-part questions as a series of additional sequential questions. With this approach, chatbots may not automatically reiterate previously explained concepts. So if you need a refresher or further explanation on a topic discussed earlier, just explicitly request during follow-up interactions._\n",
    "> \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a60d3",
   "metadata": {},
   "source": [
    "A classification decision tree is focusde on making classififcation predictions, that is, using data to predict whether an observation falls into a specific category. Some examples, predicting malignant vs benign tumors, predicting sex based on height and weight and things like that.\n",
    "\n",
    "A multiple linear regression makes a prediction on a continuous variable, which is called, rather redundantly, a regression (coming from regression to the mean and such old timey stuff). \n",
    "\n",
    "Predictions on values of continuous variables are called regression, whereas prediction on categories is called classification (which is what a classification decision tree does)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf97d1",
   "metadata": {},
   "source": [
    "### 2. Continue your ChatBot session and explore with your ChatBot what real-world application scenario(s) might be most appropriately addressed by each of the following *metrics* below: provide your answers and, in your own words, *concisely explain your rationale for your answers.*<br>\n",
    "\n",
    "\n",
    "1. **Accuracy** measures the proportion of true results (both true positives and true negatives) in the population.\n",
    "\n",
    "$$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "    \n",
    "2. **Sensitivity** measures the proportion of actual positives that are correctly identified.\n",
    "\n",
    "$$\\text{Sensitivity} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "3. **Specificity** measures the proportion of actual negatives that are correctly identified.\n",
    "\n",
    "$$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "4. **Precision** measures the proportion of positive identifications that were actually correct.\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _This question could be restated as, \"Give examples of real-world examples where each of these **metrics** would be particularly useful.\"_\n",
    ">\n",
    "> _The primary objective here is to understand the distinction between each of these **metrics**. The secondary objective is to notice how the nature of the decision-making that each of these **metrics** most naturally supports is very distinct, ideally based on identifying memorable examples that really distinguish between the **metrics**._\n",
    ">\n",
    "> - _Have a look at this (greatly expanded) handy list of additional metrics, formulas, and synonyms at the following [wikipedia page](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) if you want this to get real crazy real fast._\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278b25a",
   "metadata": {},
   "source": [
    "<small>Note: these examples are provided by the all-knowing chatgpt.</small>\n",
    "\n",
    "1. **Accuracy**: A good example is email filtering (from spam and regular mail). Since the class of email is (usually) balanced and the misclassification of either is bad (if an important email gets stuck in spam you go crazy, as well as when a spammy-terrorist email ends up in your otherwise clean email inbox), accuracy is a good metric to go by. This is because accuracy determines the proportion of correctly identified classes (both true positives and true negatives).\n",
    "\n",
    "2. **Sensitivity**: Probably the best example is disease detection. Take COVID-19 for example. The most important thing here is to minimize the rate of false negatives (positives that are incorrectly taken as negatives). So, sensitivity is the best metric to visualize here, since it measures the amount of true positives taken from the overall positives (true positives and false negatives). It is important to understand who ACTUALLY is infected. Less harm is brought from telling someone they have COVID-19 when they don't really have it as opposed to telling someone they don't have COVID-19 when they actually do (societal damage and such).\n",
    "\n",
    "3. **Specificity**: Identifying healthy people when looking for rare diseases (like cancer). Specificity is the opposite of sensitivity, so it measures the proportion of correctly identified negatives (true negatives vs. false positives). In this example, it is better to screen healthy individuals so that they don't overtake the monetary and emotional costs of a cancer diagnosis (or any other crazy disease). In this particular case, we are talking about a large population of individuals, most of whom are actually healthy. \n",
    "\n",
    "4. **Precision**: Last example: flagging transactions as fraudulent. Precision is important here because, ideally, you don't want to spend resources in investigating legal transactions that get flagged as fraudulent. Precision deals with the proportion of true positives out of all predicted positives. In this case, flagging needs to yield true positive results so that investigations can target the real fraudsters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58bd64b",
   "metadata": {},
   "source": [
    "### 3. Explore the amazon books dataset, seen previously at the start of the semester, providing some initital standard *exploratory data analysis (EDA)* and data summarization after pre-processing the dataset to meet the requirements below<br>\n",
    "\n",
    " 1. remove `Weight_oz`, `Width`, and `Height` \n",
    " 2. drop all remaining rows with `NaN` entries \n",
    " 3. set `Pub year` and `NumPages` to have the type `int`, and `Hard_or_Paper` to have the type `category`\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _`NaN` entries can't be used in their raw form with the `scikit-learn` methodologies, so we do need to remove them to proceed with our analyses._\n",
    ">     \n",
    "> _Only remove rows with `NaN` entries once you've subset to the columns you're interested in. This will minimize potentially unnecessary data loss..._\n",
    ">\n",
    "> _It would be possible to consider imputing missing data to further mitigate data loss, but the considerations for doing so are more advanced than the level of our course, so we'll not consider that for now._ \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b50624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>List Price</th>\n",
       "      <th>Amazon Price</th>\n",
       "      <th>Hard_or_Paper</th>\n",
       "      <th>NumPages</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Pub year</th>\n",
       "      <th>ISBN-10</th>\n",
       "      <th>Thick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,001 Facts that Will Scare the S#*t Out of Yo...</td>\n",
       "      <td>Cary McNeal</td>\n",
       "      <td>12.95</td>\n",
       "      <td>5.18</td>\n",
       "      <td>P</td>\n",
       "      <td>304</td>\n",
       "      <td>Adams Media</td>\n",
       "      <td>2010</td>\n",
       "      <td>1605506249</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21: Bringing Down the House - Movie Tie-In: Th...</td>\n",
       "      <td>Ben Mezrich</td>\n",
       "      <td>15.00</td>\n",
       "      <td>10.20</td>\n",
       "      <td>P</td>\n",
       "      <td>273</td>\n",
       "      <td>Free Press</td>\n",
       "      <td>2008</td>\n",
       "      <td>1416564195</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100 Best-Loved Poems (Dover Thrift Editions)</td>\n",
       "      <td>Smith</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>P</td>\n",
       "      <td>96</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>1995</td>\n",
       "      <td>486285537</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1421: The Year China Discovered America</td>\n",
       "      <td>Gavin Menzies</td>\n",
       "      <td>15.99</td>\n",
       "      <td>10.87</td>\n",
       "      <td>P</td>\n",
       "      <td>672</td>\n",
       "      <td>Harper Perennial</td>\n",
       "      <td>2008</td>\n",
       "      <td>61564893</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1493: Uncovering the New World Columbus Created</td>\n",
       "      <td>Charles C. Mann</td>\n",
       "      <td>30.50</td>\n",
       "      <td>16.77</td>\n",
       "      <td>P</td>\n",
       "      <td>720</td>\n",
       "      <td>Knopf</td>\n",
       "      <td>2011</td>\n",
       "      <td>307265722</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Where the Sidewalk Ends</td>\n",
       "      <td>Shel Silverstein</td>\n",
       "      <td>18.99</td>\n",
       "      <td>12.24</td>\n",
       "      <td>H</td>\n",
       "      <td>192</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>2004</td>\n",
       "      <td>60572345</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>White Privilege</td>\n",
       "      <td>Paula S. Rothenberg</td>\n",
       "      <td>27.55</td>\n",
       "      <td>27.55</td>\n",
       "      <td>P</td>\n",
       "      <td>160</td>\n",
       "      <td>Worth Publishers</td>\n",
       "      <td>2011</td>\n",
       "      <td>1429233443</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Why I wore lipstick</td>\n",
       "      <td>Geralyn Lucas</td>\n",
       "      <td>12.95</td>\n",
       "      <td>5.18</td>\n",
       "      <td>P</td>\n",
       "      <td>224</td>\n",
       "      <td>St Martin's Griffin</td>\n",
       "      <td>2005</td>\n",
       "      <td>031233446X</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Worlds Together, Worlds Apart: A History of th...</td>\n",
       "      <td>Robert Tignor</td>\n",
       "      <td>97.50</td>\n",
       "      <td>97.50</td>\n",
       "      <td>P</td>\n",
       "      <td>480</td>\n",
       "      <td>W. W. Norton &amp; Company</td>\n",
       "      <td>2010</td>\n",
       "      <td>393934942</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>Emily Bronte</td>\n",
       "      <td>16.99</td>\n",
       "      <td>4.95</td>\n",
       "      <td>P</td>\n",
       "      <td>344</td>\n",
       "      <td>CreatSpace</td>\n",
       "      <td>2011</td>\n",
       "      <td>1463533411</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title               Author  \\\n",
       "0    1,001 Facts that Will Scare the S#*t Out of Yo...          Cary McNeal   \n",
       "1    21: Bringing Down the House - Movie Tie-In: Th...          Ben Mezrich   \n",
       "2         100 Best-Loved Poems (Dover Thrift Editions)                Smith   \n",
       "3              1421: The Year China Discovered America        Gavin Menzies   \n",
       "4      1493: Uncovering the New World Columbus Created      Charles C. Mann   \n",
       "..                                                 ...                  ...   \n",
       "320                            Where the Sidewalk Ends     Shel Silverstein   \n",
       "321                                    White Privilege  Paula S. Rothenberg   \n",
       "322                                Why I wore lipstick        Geralyn Lucas   \n",
       "323  Worlds Together, Worlds Apart: A History of th...        Robert Tignor   \n",
       "324                                  Wuthering Heights         Emily Bronte   \n",
       "\n",
       "     List Price  Amazon Price Hard_or_Paper  NumPages               Publisher  \\\n",
       "0         12.95          5.18             P       304             Adams Media   \n",
       "1         15.00         10.20             P       273              Free Press   \n",
       "2          1.50          1.50             P        96      Dover Publications   \n",
       "3         15.99         10.87             P       672        Harper Perennial   \n",
       "4         30.50         16.77             P       720                   Knopf   \n",
       "..          ...           ...           ...       ...                     ...   \n",
       "320       18.99         12.24             H       192           HarperCollins   \n",
       "321       27.55         27.55             P       160        Worth Publishers   \n",
       "322       12.95          5.18             P       224     St Martin's Griffin   \n",
       "323       97.50         97.50             P       480  W. W. Norton & Company   \n",
       "324       16.99          4.95             P       344              CreatSpace   \n",
       "\n",
       "     Pub year     ISBN-10  Thick  \n",
       "0        2010  1605506249    0.8  \n",
       "1        2008  1416564195    0.7  \n",
       "2        1995   486285537    0.3  \n",
       "3        2008    61564893    1.6  \n",
       "4        2011   307265722    1.4  \n",
       "..        ...         ...    ...  \n",
       "320      2004    60572345    1.1  \n",
       "321      2011  1429233443    0.7  \n",
       "322      2005  031233446X    0.7  \n",
       "323      2010   393934942    0.9  \n",
       "324      2011  1463533411    1.0  \n",
       "\n",
       "[319 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "# create `ab_reduced_noNaN` based on the specs above\n",
    "\n",
    "# Remove specified columns\n",
    "ab_reduced = ab.drop(columns=[\"Weight_oz\", \"Height\", \"Width\"])\n",
    "\n",
    "# Force specified columns to have required types\n",
    "ab_reduced[\"Pub year\"] = ab_reduced[\"Pub year\"].astype(\"Int64\")  # Nullable integer for NaN handling\n",
    "ab_reduced[\"NumPages\"] = ab_reduced[\"NumPages\"].astype(\"Int64\")\n",
    "ab_reduced[\"Hard_or_Paper\"] = ab_reduced[\"Hard_or_Paper\"].astype(\"category\")\n",
    "\n",
    "# Remove rows with NaN values\n",
    "ab_reduced_noNaN = ab_reduced.dropna()\n",
    "\n",
    "ab_reduced_noNaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225c340",
   "metadata": {},
   "source": [
    "### 4. Create an 80/20 split with 80% of the data as a training set *ab_reduced_noNaN_train* and 20% of the data testing set  *ab_reduced_noNaN_test* using either *df.sample(...)* as done in TUT or using *train_test_split(...)* as done in the previous HW, and report on how many observations there are in the training data set and the test data set.<br><br>Tell a ChatBot that you are about to fit a \"scikit-learn\" *DecisionTreeClassifier* model and ask what the two steps given below are doing; then use your ChatBots help to write code to \"train\" a classification tree *clf* using only the *List Price* variable to predict whether or not a book is a hard cover or paper back book using a *max_depth* of *2*; finally use *tree.plot_tree(clf)* to explain what *predictions* are made based on *List Price* for the fitted *clf* model\n",
    "\n",
    "```python\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "```\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _To complete the final 80/20 split of the **observations** in a reproducible way, set a \"random seed\"._ \n",
    "> \n",
    "> - _A single **observation** consists of all the measurements made on a single entity, typically corresponding to a row of a data frame. In **Machine Learning**, a collection of values of interest measured for a single entity is called a \"vector\" and so the **observation** is referred to as a **vector**_.\n",
    ">    \n",
    "> _Asking the ChatBot about \"DecisionTreeClassifier .fit(...)\" can be helpful here..._\n",
    "> \n",
    "> _Should you use the \"ab_reduced_noNaN\" data, or the \"ab_reduced_noNaN_train\" data, or the \"ab_reduced_noNaN_test\" data to initially fit the classification tree? Why?_\n",
    ">    \n",
    "> _You can visualize your decision tree using the `tree.plot_tree(clf)` function shown in the `sklearn` documentation [here](\n",
    "https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#what-is-the-values-array-used-here) and [here](https://scikit-learn.org/stable/modules/tree.html); but, to make it more immediately readible it might be better to use `graphviz`, which is demonstrated in the `sklearn` documentation [here](https://scikit-learn.org/stable/modules/tree.html#alternative-ways-to-export-trees)_ \n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461c99c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision tree: 0.84\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20231125.0833)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"588pt\" height=\"346pt\"\n",
       " viewBox=\"0.00 0.00 587.50 345.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 341.5)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-341.5 583.5,-341.5 583.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#eead7e\" stroke=\"black\" d=\"M353.88,-337.5C353.88,-337.5 238.12,-337.5 238.12,-337.5 232.12,-337.5 226.12,-331.5 226.12,-325.5 226.12,-325.5 226.12,-255.25 226.12,-255.25 226.12,-249.25 232.12,-243.25 238.12,-243.25 238.12,-243.25 353.88,-243.25 353.88,-243.25 359.88,-243.25 365.88,-249.25 365.88,-255.25 365.88,-255.25 365.88,-325.5 365.88,-325.5 365.88,-331.5 359.88,-337.5 353.88,-337.5\"/>\n",
       "<text text-anchor=\"start\" x=\"234.12\" y=\"-320.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 17.97</text>\n",
       "<text text-anchor=\"start\" x=\"252.5\" y=\"-302.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.384</text>\n",
       "<text text-anchor=\"start\" x=\"243.12\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\n",
       "<text text-anchor=\"start\" x=\"234.5\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [189, 66]</text>\n",
       "<text text-anchor=\"start\" x=\"248.75\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e99254\" stroke=\"black\" d=\"M272.5,-207.25C272.5,-207.25 157.5,-207.25 157.5,-207.25 151.5,-207.25 145.5,-201.25 145.5,-195.25 145.5,-195.25 145.5,-125 145.5,-125 145.5,-119 151.5,-113 157.5,-113 157.5,-113 272.5,-113 272.5,-113 278.5,-113 284.5,-119 284.5,-125 284.5,-125 284.5,-195.25 284.5,-195.25 284.5,-201.25 278.5,-207.25 272.5,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"157.62\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 10.8</text>\n",
       "<text text-anchor=\"start\" x=\"171.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.212</text>\n",
       "<text text-anchor=\"start\" x=\"162.12\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 183</text>\n",
       "<text text-anchor=\"start\" x=\"153.5\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [161, 22]</text>\n",
       "<text text-anchor=\"start\" x=\"167.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.76,-243.07C261.42,-234.63 255.81,-225.74 250.32,-217.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"253.31,-215.22 245.01,-208.64 247.39,-218.96 253.31,-215.22\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.69\" y=\"-227.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#b7dbf6\" stroke=\"black\" d=\"M439.38,-207.25C439.38,-207.25 314.62,-207.25 314.62,-207.25 308.62,-207.25 302.62,-201.25 302.62,-195.25 302.62,-195.25 302.62,-125 302.62,-125 302.62,-119 308.62,-113 314.62,-113 314.62,-113 439.38,-113 439.38,-113 445.38,-113 451.38,-119 451.38,-125 451.38,-125 451.38,-195.25 451.38,-195.25 451.38,-201.25 445.38,-207.25 439.38,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"310.62\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 27.275</text>\n",
       "<text text-anchor=\"start\" x=\"333.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\n",
       "<text text-anchor=\"start\" x=\"328.62\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 72</text>\n",
       "<text text-anchor=\"start\" x=\"320\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 44]</text>\n",
       "<text text-anchor=\"start\" x=\"332.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M325.24,-243.07C330.58,-234.63 336.19,-225.74 341.68,-217.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.61,-218.96 346.99,-208.64 338.69,-215.22 344.61,-218.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.31\" y=\"-227.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#edaa79\" stroke=\"black\" d=\"M118,-77C118,-77 12,-77 12,-77 6,-77 0,-71 0,-65 0,-65 0,-12 0,-12 0,-6 6,0 12,0 12,0 118,0 118,0 124,0 130,-6 130,-12 130,-12 130,-65 130,-65 130,-71 124,-77 118,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.369</text>\n",
       "<text text-anchor=\"start\" x=\"16.62\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [34, 11]</text>\n",
       "<text text-anchor=\"start\" x=\"17.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.58,-112.53C144.91,-103.23 132.68,-93.47 121.09,-84.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.56,-81.72 113.56,-78.22 119.19,-87.2 123.56,-81.72\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e78c4a\" stroke=\"black\" d=\"M275.5,-77C275.5,-77 160.5,-77 160.5,-77 154.5,-77 148.5,-71 148.5,-65 148.5,-65 148.5,-12 148.5,-12 148.5,-6 154.5,0 160.5,0 160.5,0 275.5,0 275.5,0 281.5,0 287.5,-6 287.5,-12 287.5,-12 287.5,-65 287.5,-65 287.5,-71 281.5,-77 275.5,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"174.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.147</text>\n",
       "<text text-anchor=\"start\" x=\"165.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [127, 11]</text>\n",
       "<text text-anchor=\"start\" x=\"170.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M216.17,-112.53C216.37,-104.69 216.57,-96.52 216.77,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"220.26,-88.88 217.01,-78.79 213.26,-88.7 220.26,-88.88\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#80c0ee\" stroke=\"black\" d=\"M428,-77C428,-77 322,-77 322,-77 316,-77 310,-71 310,-65 310,-65 310,-12 310,-12 310,-6 316,0 322,0 322,0 428,0 428,0 434,0 440,-6 440,-12 440,-12 440,-65 440,-65 440,-71 434,-77 428,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"336\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.39</text>\n",
       "<text text-anchor=\"start\" x=\"326.62\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\n",
       "<text text-anchor=\"start\" x=\"318\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 36]</text>\n",
       "<text text-anchor=\"start\" x=\"330.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M376.22,-112.53C376.09,-104.69 375.95,-96.52 375.82,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"379.32,-88.73 375.66,-78.79 372.32,-88.85 379.32,-88.73\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#f3c4a3\" stroke=\"black\" d=\"M567.5,-77C567.5,-77 470.5,-77 470.5,-77 464.5,-77 458.5,-71 458.5,-65 458.5,-65 458.5,-12 458.5,-12 458.5,-6 464.5,0 470.5,0 470.5,0 567.5,0 567.5,0 573.5,0 579.5,-6 579.5,-12 579.5,-12 579.5,-65 579.5,-65 579.5,-71 573.5,-77 567.5,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"475.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.454</text>\n",
       "<text text-anchor=\"start\" x=\"470.62\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n",
       "<text text-anchor=\"start\" x=\"466.5\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"471.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M432.31,-112.53C443.25,-103.32 454.71,-93.66 465.58,-84.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"467.6,-87.38 473,-78.26 463.09,-82.02 467.6,-87.38\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f15aaf9d990>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode target variable ('H' for Hardback, 0/1 encoding)\n",
    "y = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H'] # Sets the target variable as 1.\n",
    "\n",
    "# Select feature (List Price)\n",
    "X = ab_reduced_noNaN[['List Price']] # Keeps it as a dataframe.\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit decision tree classifier\n",
    "clf = tree.DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the tree's performance on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy of the decision tree: {accuracy:.2f}\")\n",
    "\n",
    "# Export the tree in Graphviz format\n",
    "dot_data = tree.export_graphviz(\n",
    "    clf, \n",
    "    out_file=None, \n",
    "    feature_names=['List Price'], \n",
    "    class_names=['Paper', 'Hard'], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "# Visualize the tree using Graphviz\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da252c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes of the train and test data. (My code separated both the train and test data into x and y values)\n",
      "List Price    255\n",
      "dtype: int64\n",
      "List Price    64\n",
      "dtype: int64\n",
      "255\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print('Sizes of the train and test data. (My code separated both the train and test data into x and y values)')\n",
    "print(X_train.count())\n",
    "print(X_test.count())\n",
    "print(y_train.count())\n",
    "print(y_test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d563f15",
   "metadata": {},
   "source": [
    "#### The tree\n",
    "\n",
    "This decision tree predicts whether a book is a hard cover or paperback depending on whether the list price passes a threshold in each of the decison tree's nodes. For example, if a book's price is 15, it'll go down left first, then right (as it is not smaller or equal to 10.8). This means that it would be predicted as a paper back book.\n",
    "\n",
    "The value list shows how many observations there are of each class, and the dominant class is the one that gets the color in the node. In the last nodes, this dominant class is what gives the prediction of the tree. So, in our example of the $15 tree, it would get predicted Paperback since it falls into a node that predicts this class (notice that the last nodes don't have a threshold)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ac0e5b",
   "metadata": {},
   "source": [
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Continue now...?</u></summary>\n",
    "\n",
    "### Pre-lecture VS Post-lecture HW\n",
    "\n",
    "Feel free to work on the \"Post-lecture\" HW below if you're making good progress and want to continue: for **HW 08** this could be reasonable because, as you'll see, the process of creating and using **classification decision trees** is quite similar to the process for creating and using **multiple linear regression** models. There are differences of course, such as how there is **coefficient hypothesis testing** in **multiple linear regression** and **confusion matrices** in **classification decision trees**, and so on. But you would very likely be able to leverage the silarities to make a lot of progress with **classification decision trees** based on your experience with **multiple linear regression**.\n",
    "    \n",
    "*The benefits of continue would are that (a) Consolidate the knowledge already learned and integrate it comprehensively. (b) Let you build experience interacting with ChatBots (and understand their strengths and limitations in this regard)... it's good to have sense of when using a ChatBot is the best way to figure something out, or if another approach (such as course provided resources or a plain old websearch for the right resourse) would be more effective*\n",
    "    \n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e7d3e",
   "metadata": {},
   "source": [
    "## \"Post-lecture\" HW [*submission along with \"Pre-lecture\" HW is due prior to next TUT*]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3ce1f",
   "metadata": {},
   "source": [
    "### 5. Repeat the previous problem but this time visualize the *classification decision tree* based on the following specifications below; then explain generally how predictions are made for the *clf2* model<br>\n",
    "\n",
    "1. `X = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]`\n",
    "2. `max_depth` set to `4`\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> - _Use the same **train/test split** dataset used so far_\n",
    "> - _Train the **classification decision tree** `clf2` using **predictor variables** `NumPages`, `Thick` and `List Price`_ \n",
    "> - _Again **predict** whether or not a book is hard cover book or a paper back book_\n",
    "> - _You can visualize your decision tree using the `tree.plot_tree(clf)` function shown in the `sklearn` documentation [here](\n",
    "https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#what-is-the-values-array-used-here) and [here](https://scikit-learn.org/stable/modules/tree.html); but, to make it more immediately readible it might be better to use `graphviz`, which is demonstrated in the `sklearn` documentation [here](https://scikit-learn.org/stable/modules/tree.html#alternative-ways-to-export-trees)_\n",
    ">\n",
    "> _If you are interested in how to find the best `max_depth` for a tree, ask ChatBot about \"GridSearchCV\"_\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68edbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the decision tree: 0.86\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20231125.0833)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1256pt\" height=\"606pt\"\n",
       " viewBox=\"0.00 0.00 1256.00 606.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 602)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-602 1252,-602 1252,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#eead7e\" stroke=\"black\" d=\"M572.88,-598C572.88,-598 457.12,-598 457.12,-598 451.12,-598 445.12,-592 445.12,-586 445.12,-586 445.12,-515.75 445.12,-515.75 445.12,-509.75 451.12,-503.75 457.12,-503.75 457.12,-503.75 572.88,-503.75 572.88,-503.75 578.88,-503.75 584.88,-509.75 584.88,-515.75 584.88,-515.75 584.88,-586 584.88,-586 584.88,-592 578.88,-598 572.88,-598\"/>\n",
       "<text text-anchor=\"start\" x=\"453.12\" y=\"-580.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 17.97</text>\n",
       "<text text-anchor=\"start\" x=\"471.5\" y=\"-563.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.384</text>\n",
       "<text text-anchor=\"start\" x=\"462.12\" y=\"-546.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\n",
       "<text text-anchor=\"start\" x=\"453.5\" y=\"-528.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [189, 66]</text>\n",
       "<text text-anchor=\"start\" x=\"467.75\" y=\"-511.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#e99254\" stroke=\"black\" d=\"M493,-467.75C493,-467.75 375,-467.75 375,-467.75 369,-467.75 363,-461.75 363,-455.75 363,-455.75 363,-385.5 363,-385.5 363,-379.5 369,-373.5 375,-373.5 375,-373.5 493,-373.5 493,-373.5 499,-373.5 505,-379.5 505,-385.5 505,-385.5 505,-455.75 505,-455.75 505,-461.75 499,-467.75 493,-467.75\"/>\n",
       "<text text-anchor=\"start\" x=\"371\" y=\"-450.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">NumPages ≤ 82.0</text>\n",
       "<text text-anchor=\"start\" x=\"390.5\" y=\"-433.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.212</text>\n",
       "<text text-anchor=\"start\" x=\"381.12\" y=\"-415.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 183</text>\n",
       "<text text-anchor=\"start\" x=\"372.5\" y=\"-398.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [161, 22]</text>\n",
       "<text text-anchor=\"start\" x=\"386.75\" y=\"-381.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M485.76,-503.57C480.42,-495.13 474.81,-486.24 469.32,-477.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"472.31,-475.72 464.01,-469.14 466.39,-479.46 472.31,-475.72\"/>\n",
       "<text text-anchor=\"middle\" x=\"457.69\" y=\"-487.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#b7dbf6\" stroke=\"black\" d=\"M714,-467.75C714,-467.75 608,-467.75 608,-467.75 602,-467.75 596,-461.75 596,-455.75 596,-455.75 596,-385.5 596,-385.5 596,-379.5 602,-373.5 608,-373.5 608,-373.5 714,-373.5 714,-373.5 720,-373.5 726,-379.5 726,-385.5 726,-385.5 726,-455.75 726,-455.75 726,-461.75 720,-467.75 714,-467.75\"/>\n",
       "<text text-anchor=\"start\" x=\"616.38\" y=\"-450.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Thick ≤ 0.95</text>\n",
       "<text text-anchor=\"start\" x=\"617.5\" y=\"-433.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\n",
       "<text text-anchor=\"start\" x=\"612.62\" y=\"-415.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 72</text>\n",
       "<text text-anchor=\"start\" x=\"604\" y=\"-398.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 44]</text>\n",
       "<text text-anchor=\"start\" x=\"616.75\" y=\"-381.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>0&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567.71,-503.57C578.15,-494.4 589.19,-484.7 599.89,-475.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"602.03,-478.09 607.23,-468.86 597.41,-472.83 602.03,-478.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"606.75\" y=\"-488.13\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#88c4ef\" stroke=\"black\" d=\"M230,-337.5C230,-337.5 142,-337.5 142,-337.5 136,-337.5 130,-331.5 130,-325.5 130,-325.5 130,-255.25 130,-255.25 130,-249.25 136,-243.25 142,-243.25 142,-243.25 230,-243.25 230,-243.25 236,-243.25 242,-249.25 242,-255.25 242,-255.25 242,-325.5 242,-325.5 242,-331.5 236,-337.5 230,-337.5\"/>\n",
       "<text text-anchor=\"start\" x=\"141.38\" y=\"-320.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Thick ≤ 0.25</text>\n",
       "<text text-anchor=\"start\" x=\"142.5\" y=\"-302.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n",
       "<text text-anchor=\"start\" x=\"142.12\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n",
       "<text text-anchor=\"start\" x=\"138\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"141.75\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M362.6,-382.7C327.83,-364.72 286.28,-343.23 252.22,-325.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.2,-322.7 243.71,-321.22 250.99,-328.92 254.2,-322.7\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#e88e4e\" stroke=\"black\" d=\"M491.5,-337.5C491.5,-337.5 376.5,-337.5 376.5,-337.5 370.5,-337.5 364.5,-331.5 364.5,-325.5 364.5,-325.5 364.5,-255.25 364.5,-255.25 364.5,-249.25 370.5,-243.25 376.5,-243.25 376.5,-243.25 491.5,-243.25 491.5,-243.25 497.5,-243.25 503.5,-249.25 503.5,-255.25 503.5,-255.25 503.5,-325.5 503.5,-325.5 503.5,-331.5 497.5,-337.5 491.5,-337.5\"/>\n",
       "<text text-anchor=\"start\" x=\"389.38\" y=\"-320.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Thick ≤ 1.65</text>\n",
       "<text text-anchor=\"start\" x=\"390.5\" y=\"-302.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.175</text>\n",
       "<text text-anchor=\"start\" x=\"381.12\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 176</text>\n",
       "<text text-anchor=\"start\" x=\"372.5\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [159, 17]</text>\n",
       "<text text-anchor=\"start\" x=\"386.75\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M434,-373.32C434,-365.42 434,-357.13 434,-348.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"437.5,-349.12 434,-339.12 430.5,-349.12 437.5,-349.12\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M100,-198.62C100,-198.62 12,-198.62 12,-198.62 6,-198.62 0,-192.62 0,-186.62 0,-186.62 0,-133.62 0,-133.62 0,-127.62 6,-121.62 12,-121.62 12,-121.62 100,-121.62 100,-121.62 106,-121.62 112,-127.62 112,-133.62 112,-133.62 112,-186.62 112,-186.62 112,-192.62 106,-198.62 100,-198.62\"/>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-181.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"12.12\" y=\"-164.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-146.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"8.75\" y=\"-129.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.07,-243.07C127.13,-231.3 114.31,-218.65 102.4,-206.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.98,-204.53 95.4,-200 100.06,-209.51 104.98,-204.53\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M230,-198.62C230,-198.62 142,-198.62 142,-198.62 136,-198.62 130,-192.62 130,-186.62 130,-186.62 130,-133.62 130,-133.62 130,-127.62 136,-121.62 142,-121.62 142,-121.62 230,-121.62 230,-121.62 236,-121.62 242,-127.62 242,-133.62 242,-133.62 242,-186.62 242,-186.62 242,-192.62 236,-198.62 230,-198.62\"/>\n",
       "<text text-anchor=\"start\" x=\"151.5\" y=\"-181.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"142.12\" y=\"-164.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"138\" y=\"-146.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n",
       "<text text-anchor=\"start\" x=\"141.75\" y=\"-129.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186,-243.07C186,-232.43 186,-221.08 186,-210.31\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.5,-210.45 186,-200.45 182.5,-210.45 189.5,-210.45\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#e88e4d\" stroke=\"black\" d=\"M387.5,-207.25C387.5,-207.25 272.5,-207.25 272.5,-207.25 266.5,-207.25 260.5,-201.25 260.5,-195.25 260.5,-195.25 260.5,-125 260.5,-125 260.5,-119 266.5,-113 272.5,-113 272.5,-113 387.5,-113 387.5,-113 393.5,-113 399.5,-119 399.5,-125 399.5,-125 399.5,-195.25 399.5,-195.25 399.5,-201.25 393.5,-207.25 387.5,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"285.38\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Thick ≤ 0.55</text>\n",
       "<text text-anchor=\"start\" x=\"286.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.166</text>\n",
       "<text text-anchor=\"start\" x=\"277.12\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 175</text>\n",
       "<text text-anchor=\"start\" x=\"268.5\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [159, 16]</text>\n",
       "<text text-anchor=\"start\" x=\"282.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M396.45,-243.07C389.38,-234.36 381.93,-225.16 374.67,-216.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.46,-214.1 368.44,-208.53 372.02,-218.51 377.46,-214.1\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M518,-198.62C518,-198.62 430,-198.62 430,-198.62 424,-198.62 418,-192.62 418,-186.62 418,-186.62 418,-133.62 418,-133.62 418,-127.62 424,-121.62 430,-121.62 430,-121.62 518,-121.62 518,-121.62 524,-121.62 530,-127.62 530,-133.62 530,-133.62 530,-186.62 530,-186.62 530,-192.62 524,-198.62 518,-198.62\"/>\n",
       "<text text-anchor=\"start\" x=\"439.5\" y=\"-181.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"430.12\" y=\"-164.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"426\" y=\"-146.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"429.75\" y=\"-129.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M448.44,-243.07C451.83,-232.2 455.45,-220.59 458.87,-209.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"462.12,-210.97 461.76,-200.38 455.44,-208.88 462.12,-210.97\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M239.5,-77C239.5,-77 142.5,-77 142.5,-77 136.5,-77 130.5,-71 130.5,-65 130.5,-65 130.5,-12 130.5,-12 130.5,-6 136.5,0 142.5,0 142.5,0 239.5,0 239.5,0 245.5,0 251.5,-6 251.5,-12 251.5,-12 251.5,-65 251.5,-65 251.5,-71 245.5,-77 239.5,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"142.62\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n",
       "<text text-anchor=\"start\" x=\"138.5\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [32, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"143.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>6&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M275.86,-112.53C265.26,-103.41 254.16,-93.85 243.61,-84.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.91,-82.14 236.05,-78.27 241.34,-87.44 245.91,-82.14\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#e89152\" stroke=\"black\" d=\"M396.5,-77C396.5,-77 281.5,-77 281.5,-77 275.5,-77 269.5,-71 269.5,-65 269.5,-65 269.5,-12 269.5,-12 269.5,-6 275.5,0 281.5,0 281.5,0 396.5,0 396.5,0 402.5,0 408.5,-6 408.5,-12 408.5,-12 408.5,-65 408.5,-65 408.5,-71 402.5,-77 396.5,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"295.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.199</text>\n",
       "<text text-anchor=\"start\" x=\"286.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 143</text>\n",
       "<text text-anchor=\"start\" x=\"277.5\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [127, 16]</text>\n",
       "<text text-anchor=\"start\" x=\"291.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.51,-112.53C334.1,-104.69 334.71,-96.52 335.3,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"338.78,-89.02 336.04,-78.79 331.8,-88.5 338.78,-89.02\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#efb184\" stroke=\"black\" d=\"M724.5,-337.5C724.5,-337.5 597.5,-337.5 597.5,-337.5 591.5,-337.5 585.5,-331.5 585.5,-325.5 585.5,-325.5 585.5,-255.25 585.5,-255.25 585.5,-249.25 591.5,-243.25 597.5,-243.25 597.5,-243.25 724.5,-243.25 724.5,-243.25 730.5,-243.25 736.5,-249.25 736.5,-255.25 736.5,-255.25 736.5,-325.5 736.5,-325.5 736.5,-331.5 730.5,-337.5 724.5,-337.5\"/>\n",
       "<text text-anchor=\"start\" x=\"593.5\" y=\"-320.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">NumPages ≤ 228.0</text>\n",
       "<text text-anchor=\"start\" x=\"626.5\" y=\"-302.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.4</text>\n",
       "<text text-anchor=\"start\" x=\"612.62\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n",
       "<text text-anchor=\"start\" x=\"608.5\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"613.75\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>10&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M661,-373.32C661,-365.42 661,-357.13 661,-348.98\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"664.5,-349.12 661,-339.12 657.5,-349.12 664.5,-349.12\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"#5fb0ea\" stroke=\"black\" d=\"M977.5,-337.5C977.5,-337.5 850.5,-337.5 850.5,-337.5 844.5,-337.5 838.5,-331.5 838.5,-325.5 838.5,-325.5 838.5,-255.25 838.5,-255.25 838.5,-249.25 844.5,-243.25 850.5,-243.25 850.5,-243.25 977.5,-243.25 977.5,-243.25 983.5,-243.25 989.5,-249.25 989.5,-255.25 989.5,-255.25 989.5,-325.5 989.5,-325.5 989.5,-331.5 983.5,-337.5 977.5,-337.5\"/>\n",
       "<text text-anchor=\"start\" x=\"846.5\" y=\"-320.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">NumPages ≤ 632.0</text>\n",
       "<text text-anchor=\"start\" x=\"870.5\" y=\"-302.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.273</text>\n",
       "<text text-anchor=\"start\" x=\"865.62\" y=\"-285.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\n",
       "<text text-anchor=\"start\" x=\"861.5\" y=\"-268.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 36]</text>\n",
       "<text text-anchor=\"start\" x=\"869.75\" y=\"-251.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>10&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M726.48,-386.43C757.4,-370.76 794.71,-351.85 827.88,-335.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"829.34,-338.21 836.68,-330.57 826.18,-331.97 829.34,-338.21\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e6f3fc\" stroke=\"black\" d=\"M684.38,-207.25C684.38,-207.25 559.62,-207.25 559.62,-207.25 553.62,-207.25 547.62,-201.25 547.62,-195.25 547.62,-195.25 547.62,-125 547.62,-125 547.62,-119 553.62,-113 559.62,-113 559.62,-113 684.38,-113 684.38,-113 690.38,-113 696.38,-119 696.38,-125 696.38,-125 696.38,-195.25 696.38,-195.25 696.38,-201.25 690.38,-207.25 684.38,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"555.62\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 25.975</text>\n",
       "<text text-anchor=\"start\" x=\"578.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.498</text>\n",
       "<text text-anchor=\"start\" x=\"573.62\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n",
       "<text text-anchor=\"start\" x=\"574\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 8]</text>\n",
       "<text text-anchor=\"start\" x=\"577.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M646.92,-243.07C644.46,-234.99 641.88,-226.5 639.35,-218.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"642.76,-217.36 636.5,-208.81 636.06,-219.39 642.76,-217.36\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M823.5,-198.62C823.5,-198.62 726.5,-198.62 726.5,-198.62 720.5,-198.62 714.5,-192.62 714.5,-186.62 714.5,-186.62 714.5,-133.62 714.5,-133.62 714.5,-127.62 720.5,-121.62 726.5,-121.62 726.5,-121.62 823.5,-121.62 823.5,-121.62 829.5,-121.62 835.5,-127.62 835.5,-133.62 835.5,-133.62 835.5,-186.62 835.5,-186.62 835.5,-192.62 829.5,-198.62 823.5,-198.62\"/>\n",
       "<text text-anchor=\"start\" x=\"740.5\" y=\"-181.32\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"726.62\" y=\"-164.07\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n",
       "<text text-anchor=\"start\" x=\"722.5\" y=\"-146.82\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 0]</text>\n",
       "<text text-anchor=\"start\" x=\"727.75\" y=\"-129.57\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>11&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M702.16,-243.07C712.52,-231.41 723.65,-218.89 734.01,-207.24\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"736.36,-209.86 740.39,-200.06 731.13,-205.21 736.36,-209.86\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#5aade9\" stroke=\"black\" d=\"M549,-77C549,-77 461,-77 461,-77 455,-77 449,-71 449,-65 449,-65 449,-12 449,-12 449,-6 455,0 461,0 461,0 549,0 549,0 555,0 561,-6 561,-12 561,-12 561,-65 561,-65 561,-71 555,-77 549,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"461.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n",
       "<text text-anchor=\"start\" x=\"461.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n",
       "<text text-anchor=\"start\" x=\"457\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 6]</text>\n",
       "<text text-anchor=\"start\" x=\"460.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M576.43,-112.53C567.69,-103.59 558.54,-94.24 549.82,-85.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"552.5,-83.06 543.01,-78.36 547.5,-87.96 552.5,-83.06\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#eeab7b\" stroke=\"black\" d=\"M679,-77C679,-77 591,-77 591,-77 585,-77 579,-71 579,-65 579,-65 579,-12 579,-12 579,-6 585,0 591,0 591,0 679,0 679,0 685,0 691,-6 691,-12 691,-12 691,-65 691,-65 691,-71 685,-77 679,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"591.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n",
       "<text text-anchor=\"start\" x=\"591.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n",
       "<text text-anchor=\"start\" x=\"587\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"587.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>12&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M627.06,-112.53C627.92,-104.69 628.8,-96.52 629.66,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"633.13,-89.11 630.73,-78.79 626.17,-88.35 633.13,-89.11\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<path fill=\"#4aa6e7\" stroke=\"black\" d=\"M962.5,-207.25C962.5,-207.25 865.5,-207.25 865.5,-207.25 859.5,-207.25 853.5,-201.25 853.5,-195.25 853.5,-195.25 853.5,-125 853.5,-125 853.5,-119 859.5,-113 865.5,-113 865.5,-113 962.5,-113 962.5,-113 968.5,-113 974.5,-119 974.5,-125 974.5,-125 974.5,-195.25 974.5,-195.25 974.5,-201.25 968.5,-207.25 962.5,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"869.38\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Thick ≤ 1.05</text>\n",
       "<text text-anchor=\"start\" x=\"870.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.149</text>\n",
       "<text text-anchor=\"start\" x=\"865.62\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\n",
       "<text text-anchor=\"start\" x=\"861.5\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 34]</text>\n",
       "<text text-anchor=\"start\" x=\"869.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>16&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M914,-243.07C914,-235.17 914,-226.88 914,-218.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"917.5,-218.87 914,-208.87 910.5,-218.87 917.5,-218.87\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1129.38,-207.25C1129.38,-207.25 1004.62,-207.25 1004.62,-207.25 998.62,-207.25 992.62,-201.25 992.62,-195.25 992.62,-195.25 992.62,-125 992.62,-125 992.62,-119 998.62,-113 1004.62,-113 1004.62,-113 1129.38,-113 1129.38,-113 1135.38,-113 1141.38,-119 1141.38,-125 1141.38,-125 1141.38,-195.25 1141.38,-195.25 1141.38,-201.25 1135.38,-207.25 1129.38,-207.25\"/>\n",
       "<text text-anchor=\"start\" x=\"1000.62\" y=\"-189.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">List Price ≤ 64.725</text>\n",
       "<text text-anchor=\"start\" x=\"1023.5\" y=\"-172.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"1023.12\" y=\"-155.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n",
       "<text text-anchor=\"start\" x=\"1019\" y=\"-138.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n",
       "<text text-anchor=\"start\" x=\"1019.75\" y=\"-120.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>16&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M969.24,-243.07C980.22,-233.87 991.83,-224.13 1003.08,-214.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1005.01,-217.65 1010.43,-208.55 1000.52,-212.29 1005.01,-217.65\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<path fill=\"#9ccef2\" stroke=\"black\" d=\"M827,-77C827,-77 739,-77 739,-77 733,-77 727,-71 727,-65 727,-65 727,-12 727,-12 727,-6 733,0 739,0 739,0 827,0 827,0 833,0 839,-6 839,-12 839,-12 839,-65 839,-65 839,-71 833,-77 827,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"739.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n",
       "<text text-anchor=\"start\" x=\"739.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n",
       "<text text-anchor=\"start\" x=\"735\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 6]</text>\n",
       "<text text-anchor=\"start\" x=\"738.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>17&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M862.98,-112.53C852.99,-103.41 842.52,-93.85 832.58,-84.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"835.24,-82.46 825.49,-78.3 830.52,-87.63 835.24,-82.46\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M966.5,-77C966.5,-77 869.5,-77 869.5,-77 863.5,-77 857.5,-71 857.5,-65 857.5,-65 857.5,-12 857.5,-12 857.5,-6 863.5,0 869.5,0 869.5,0 966.5,0 966.5,0 972.5,0 978.5,-6 978.5,-12 978.5,-12 978.5,-65 978.5,-65 978.5,-71 972.5,-77 966.5,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"883.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"869.62\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n",
       "<text text-anchor=\"start\" x=\"865.5\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 28]</text>\n",
       "<text text-anchor=\"start\" x=\"873.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M915.56,-112.53C915.82,-104.69 916.09,-96.52 916.36,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"919.85,-88.9 916.69,-78.79 912.85,-88.67 919.85,-88.9\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<path fill=\"#eca06a\" stroke=\"black\" d=\"M1106,-77C1106,-77 1018,-77 1018,-77 1012,-77 1006,-71 1006,-65 1006,-65 1006,-12 1006,-12 1006,-6 1012,0 1018,0 1018,0 1106,0 1106,0 1112,0 1118,-6 1118,-12 1118,-12 1118,-65 1118,-65 1118,-71 1112,-77 1106,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"1023\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n",
       "<text text-anchor=\"start\" x=\"1018.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n",
       "<text text-anchor=\"start\" x=\"1014\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"1014.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Paper</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;21 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>20&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1065.05,-112.53C1064.72,-104.69 1064.38,-96.52 1064.05,-88.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1067.56,-88.64 1063.64,-78.79 1060.56,-88.93 1067.56,-88.64\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>22</title>\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1236,-77C1236,-77 1148,-77 1148,-77 1142,-77 1136,-71 1136,-65 1136,-65 1136,-12 1136,-12 1136,-6 1142,0 1148,0 1148,0 1236,0 1236,0 1242,0 1248,-6 1248,-12 1248,-12 1248,-65 1248,-65 1248,-71 1242,-77 1236,-77\"/>\n",
       "<text text-anchor=\"start\" x=\"1157.5\" y=\"-59.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"start\" x=\"1148.12\" y=\"-42.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n",
       "<text text-anchor=\"start\" x=\"1144\" y=\"-25.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n",
       "<text text-anchor=\"start\" x=\"1147.75\" y=\"-7.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = Hard</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;22 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>20&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1115.69,-112.53C1125.12,-103.5 1135,-94.05 1144.41,-85.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1146.62,-87.77 1151.43,-78.33 1141.78,-82.71 1146.62,-87.77\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f162144b790>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]\n",
    "y_2 = pd.get_dummies(ab_reduced_noNaN[\"Hard_or_Paper\"])['H']\n",
    "\n",
    "# Train-test split (80% train, 20% test) with new X\n",
    "X_2train, X_2test, y_2train, y_2test = train_test_split(X_2, y_2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit decision tree classifier\n",
    "clf2 = tree.DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf2 = clf2.fit(X_2train, y_2train)\n",
    "\n",
    "# Print the tree's performance on the test set\n",
    "y_2pred = clf2.predict(X_2test)\n",
    "accuracy = accuracy_score(y_2test, y_2pred)\n",
    "\n",
    "print(f\"Accuracy of the decision tree: {accuracy:.2f}\")\n",
    "\n",
    "# Export the tree in Graphviz format\n",
    "dot_data2 = tree.export_graphviz(\n",
    "    clf2, \n",
    "    out_file=None, \n",
    "    feature_names=['NumPages', 'Thick', 'List Price'], \n",
    "    class_names=['Paper', 'Hard'], \n",
    "    filled=True, \n",
    "    rounded=True, \n",
    "    special_characters=True\n",
    ")\n",
    "\n",
    "# Visualize the tree using Graphviz\n",
    "graph2 = gv.Source(dot_data2)\n",
    "graph2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889386a",
   "metadata": {},
   "source": [
    "### 6. Use previously created *ab_reduced_noNaN_test* to create confusion matrices for *clf* and *clf2*. Report the sensitivity, specificity and accuracy for each of the models<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Hopefully you immediately thought to ask ChatBot to help you with this problem, but if you did you should take time to make sure you're clear about the key components of what the ChatBot is providing for you. You might want to know_\n",
    "> - _what is a \"positive\" and what is a \"negative\"_\n",
    "> - _how to read an `sklearn` confusion matrix_\n",
    "> - _what leads to TP, TN, FP, and FN_\n",
    "> - _whether `y_true` or `y_pred` go first in the `confusion_matrix` function_   \n",
    ">\n",
    "> _Have the visualizations you make use decimal numbers with three signifiant digits, such as `0.123` (and not as percentages like `12.3%`), probably based on `np.round()`_\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "       \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478c45ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for clf:\n",
      "[[40  4]\n",
      " [ 6 14]]\n",
      "Confusion Matrix for clf2:\n",
      "[[40  4]\n",
      " [ 5 15]]\n",
      "clf Metrics:\n",
      "Accuracy: 0.844, Sensitivity: 0.700, Specificity: 0.909, Precision: 0.778\n",
      "clf2 Metrics:\n",
      "Accuracy: 0.859, Sensitivity: 0.750, Specificity: 0.909, Precision: 0.789\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix for clf\n",
    "cm_clf = confusion_matrix(y_test, y_pred)\n",
    "disp_clf = ConfusionMatrixDisplay(confusion_matrix=cm_clf, display_labels=['Paper', 'Hard'])\n",
    "disp_clf.plot(cmap='Blues', values_format='.3g')  # Three significant digits\n",
    "print(\"Confusion Matrix for clf:\")\n",
    "print(cm_clf)\n",
    "\n",
    "# Confusion matrix for clf2\n",
    "cm_clf2 = confusion_matrix(y_2test, y_2pred)\n",
    "disp_clf2 = ConfusionMatrixDisplay(confusion_matrix=cm_clf2, display_labels=['Paper', 'Hard'])\n",
    "disp_clf2.plot(cmap='Blues', values_format='.3g')  # Three significant digits\n",
    "print(\"Confusion Matrix for clf2:\")\n",
    "print(cm_clf2)\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(cm):\n",
    "    TN, FP, FN, TP = cm.ravel()  # Unpack confusion matrix values\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    return accuracy, sensitivity, specificity, precision\n",
    "\n",
    "# Metrics for clf\n",
    "accuracy_clf, sensitivity_clf, specificity_clf, precision_clf = compute_metrics(cm_clf)\n",
    "print(f\"clf Metrics:\\nAccuracy: {accuracy_clf:.3f}, Sensitivity: {sensitivity_clf:.3f}, Specificity: {specificity_clf:.3f}, Precision: {precision_clf:.3f}\")\n",
    "\n",
    "# Metrics for clf2\n",
    "accuracy_clf2, sensitivity_clf2, specificity_clf2, precision_clf2 = compute_metrics(cm_clf2)\n",
    "print(f\"clf2 Metrics:\\nAccuracy: {accuracy_clf2:.3f}, Sensitivity: {sensitivity_clf2:.3f}, Specificity: {specificity_clf2:.3f}, Precision: {precision_clf2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72576c25",
   "metadata": {},
   "source": [
    "### 7. Explain in three to four sentences what is causing the differences between the following two confusion matrices below, and why the two confusion matrices above (for *clf* and *clf2*) are better<br>\n",
    "\n",
    "```python\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(ab_reduced_noNaN_train.life_exp_good, \n",
    "                     clf.predict(ab_reduced_noNaN_train[['List Price']]), \n",
    "                     labels=[0, 1]), display_labels=[\"Paper\",\"Hard\"]).plot()\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(ab_reduced_noNaN_train.life_exp_good, \n",
    "                     clf.predict(\n",
    "                         ab_reduced_noNaN_train[['NumPages','Thick','List Price']]), \n",
    "                     labels=[0, 1]), display_labels=[\"Paper\",\"Hard\"]).plot()\n",
    "```\n",
    "\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "    \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068e4ae",
   "metadata": {},
   "source": [
    "#### The verdict\n",
    "\n",
    "The difference between these two matrices is the amount of predictor variables (list price vs. num pages, list price and thick). One model is simple, one is complex. The problem with these confusion matrices is that the model from which they are drawing information is based only on training data, or 'seen' data, as opposed to the earlier models which are tested on 'unseen' data. This means that the earlier matrices are making predicions based on this 'unseen' data, which allows us to get a better indicator of whether our model is performing well or not (whether or not it is generalizable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d0ca68",
   "metadata": {},
   "source": [
    "# The ChatGPT conversation\n",
    "\n",
    "### Summary of Our Conversation\n",
    "\n",
    "#### **1. Decision Trees and Their Applications**\n",
    "- We discussed the types of problems decision trees solve (classification and regression).\n",
    "- Key concepts like splitting, max depth, and feature selection were introduced.\n",
    "\n",
    "#### **2. Statistical Metrics**\n",
    "- Explored **accuracy, sensitivity, specificity, and precision** with real-world examples:\n",
    "  - **Accuracy**: Balanced evaluation.\n",
    "  - **Sensitivity**: Identifying true positives.\n",
    "  - **Specificity**: Avoiding false positives.\n",
    "  - **Precision**: Use when false positives are costly.\n",
    "\n",
    "#### **3. Preprocessing and Feature Engineering**\n",
    "- Demonstrated how to:\n",
    "  - Remove columns (`Width`, `Weight_oz`, `Height`) from the dataset.\n",
    "  - Convert `Pub year` and `NumPages` to integers, and `Hard_or_Paper` to a categorical variable.\n",
    "\n",
    "#### **4. Splitting and Modeling**\n",
    "- Created an 80/20 train-test split using `train_test_split`.\n",
    "- Built a decision tree (`clf`) with `max_depth=2`, predicting `Hard_or_Paper` using only `List Price`.\n",
    "- Discussed:\n",
    "  - Encoding the target variable (`pd.get_dummies`) and selecting features (`[['List Price']]`).\n",
    "  - Importance of reproducibility with `random_state`.\n",
    "\n",
    "#### **5. Visualizing Decision Trees**\n",
    "- Used `Graphviz` to plot decision trees.\n",
    "- Ensured reproducibility by adding a random seed (`random_state=42`) to the model.\n",
    "\n",
    "#### **6. Hyperparameter Tuning**\n",
    "- Introduced `GridSearchCV` for optimizing `max_depth` and other parameters.\n",
    "- Highlighted how it evaluates combinations of hyperparameters using cross-validation.\n",
    "\n",
    "#### **7. Confusion Matrices**\n",
    "- Built confusion matrices for both `clf` and `clf2`:\n",
    "  - Displayed results with three significant digits using `ConfusionMatrixDisplay`.\n",
    "  - Calculated metrics (accuracy, sensitivity, specificity, precision) for both models.\n",
    "\n",
    "#### **8. Comparing Approaches**\n",
    "- Analyzed the provided code for confusion matrices on training data:\n",
    "  - First matrix used `List Price` as the sole feature.\n",
    "  - Second matrix included `NumPages`, `Thick`, and `List Price`.\n",
    "- Highlighted why earlier code (evaluating on test data) is superior:\n",
    "  - Generalization on unseen data.\n",
    "  - Reproducibility via `train_test_split`.\n",
    "  - Avoids overfitting.\n",
    "\n",
    "Let me know if you'd like further clarification or assistance!\n",
    "\n",
    "[The chatty chat chat in question.](https://chatgpt.com/share/673f54e2-b220-800b-8042-d91a373987fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526939c2",
   "metadata": {},
   "source": [
    "\n",
    "### 8. Read the paragraphs in *Further Guidance* and ask a ChatBot how to visualize *feature Importances* available for *scikit-learn* *classification decision trees*; do so for *clf2*;  and use *.feature_names_in_* corresponding to *.feature_importances_* to report which *predictor variable* is most important for making predictions according to *clf2*<br>\n",
    "\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "  \n",
    "> The way a **classification decision tree** is fit is that at each step in the construction process of adding a new **decision node splitting rule** to the current **tree structure**, all possible **decision rules** for all possible **predictor variables** are considered, and the combination that improves the **prediction** the most (as measured by the criterion of either \"Gini impurity\" or \"Shannon entropy\") and in accordance with the rules of the decision tree (such as the `max_depth` argument) is added to the **classification decision tree**.  Thus overall \"criterion\" noted above improves with each new **decision node splitting rule**, so the improvement can thus be tracked and the improvement contributions attributed to the **feature** upon which the **decision node splitting rule** is based.  This means the relative contribution of each **predictor variable** to the overall explanatory power of the model can be calculated, and this is what the `.feature_importances_` attribute does. \n",
    ">\n",
    "> Compared to the simplicity of understanding how different **covariates** contribute towards the final **predicted values** of **multiple linear regression models** (by just reading off the equation to see how predictions work), the the complexity of how all the different **features** interact and combine to together to create the final **predictions** from **classification decision trees** can be staggering. But the so-called **feature importance** heuristics allows us to judge how relatively important the overall contributions from different features are in the final decision tree predictions. Now we just need to be sure we're not **overfitting** our **classification decision trees** since they can be so **complex**. Fortunately, the \"GridSearchCV\" methodology mentioned in regards to finding the best `max_depth` setting for a tree is going to provide a general answer to the challenge of complexity and **overfitting** in **machine learning models** that is not too hard to understand (and which you might already have some guesses or a hunch about). \n",
    "> \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "       \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7d92c",
   "metadata": {},
   "source": [
    "### 9. Describe the differences of interpreting coefficients in linear model regression versus feature importances in decision trees in two to three sentences<br>\n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    "> _Linear model regression predicts continuous real-valued averages for a given configuration of covariate values (or, feature values, if we're using machine learning terminology instead of statistical terminology), whereas a binary classification model such as a binary classification tree predicts 0/1 (\"yes\" or \"no\") outcomes (and gives the probability of a 1 \"yes\" (or \"success\") outcome from which a 1/0 \"yes\"/\"no\" prediction can be made; but, this is not what is being asked here. This question is asking \"what's the difference in the way we can interpret and understand how the predictor variables influence the predictions in linear model regression based on the coefficients versus in binary decision trees based on the Feature Importances?\"_\n",
    ">    \n",
    "> ---\n",
    "> \n",
    "> _Don't forget to ask for summaries of all your different ChatBot sessions and organize and paste these into your homework notebook (including link(s) to chat log histories if you're using ChatBot); but, if you're using the STA130 custom NBLM ChatBot, you'll only be able to ask for summaries, of course!_ \n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6fb0cb",
   "metadata": {},
   "source": [
    "### 10. Have you reviewed the course wiki-textbook and interacted with a ChatBot (or, if that wasn't sufficient, real people in the course piazza discussion board or TA office hours) to help you understand all the material in the tutorial and lecture that you didn't quite follow when you first saw it?<br>\n",
    "  \n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Further Guidance</u></summary>\n",
    "\n",
    ">  _Here is the link of [wiki-textbook](https://github.com/pointOfive/stat130chat130/wiki) in case it gets lost among all the information you need to keep track of_  : )\n",
    "> \n",
    "> _Just answering \"Yes\" or \"No\" or \"Somewhat\" or \"Mostly\" or whatever here is fine as this question isn't a part of the rubric; but, the midterm and final exams may ask questions that are based on the tutorial and lecture materials; and, your own skills will be limited by your familiarity with these materials (which will determine your ability to actually do actual things effectively with these skills... like the course project...)_\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2436778",
   "metadata": {},
   "source": [
    "# Recommended Additional Useful Activities [Optional]\n",
    "\n",
    "The \"Ethical Profesionalism Considerations\" and \"Current Course Project Capability Level\" sections below **are not a part of the required homework assignment**; rather, they are regular weekly guides covering (a) relevant considerations regarding professional and ethical conduct, and (b) the analysis steps for the STA130 course project that are feasible at the current stage of the course \n",
    "\n",
    "<br>\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Ethical Professionalism Considerations</u></summary>\n",
    "\n",
    "### Ethical Professionalism Considerations\n",
    "\n",
    "- Discuss with a ChatBox about consent and data collection for training models.\n",
    "    - Discuss the ethics of data collection for training decision trees, particularly the need for informed consent when personal data is involved.\n",
    "    - Evaluate the role of regulatory frameworks in ensuring ethical data collection practices.\n",
    "- Discuss with a ChatBox about accountability in automated decision-making.\n",
    "    - Address the challenges of holding systems and their developers accountable when decision trees lead to adverse outcomes.\n",
    "    - Explore legal and ethical frameworks for responsibility when automated decisions go wrong.\n",
    "- Discuss with a ChatBox about transparency and explainability in classification models.\n",
    "    - Discuss the importance of model transparency, particularly when using decision trees in sectors like healthcare or criminal justice.\n",
    "    - Explore methods to enhance the explainability of decision trees, such as visualization techniques and simplified decision paths.\n",
    "- Discuss with a ChatBox about impact of misclassifications in critical applications.\n",
    "    - Examine the consequences of false positives and false negatives in decision tree outcomes, using confusion matrices to highlight these issues.\n",
    "    - Discuss ethical responsibilities when deploying classifiers in high-stakes fields like medicine or law enforcement.\n",
    "    \n",
    "</details>    \n",
    "\n",
    "<details class=\"details-example\"><summary style=\"color:blue\"><u>Current Course Project Capability Level</u></summary>\n",
    "\n",
    "**Remember to abide by the [data use agreement](https://static1.squarespace.com/static/60283c2e174c122f8ebe0f39/t/6239c284d610f76fed5a2e69/1647952517436/Data+Use+Agreement+for+the+Canadian+Social+Connection+Survey.pdf) at all times.**\n",
    "\n",
    "Information about the course project is available on the course github repo [here](https://github.com/pointOfive/stat130chat130/tree/main/CP), including a draft [course project specfication](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F23_course_project_specification.ipynb) (subject to change). \n",
    "- The Week 01 HW introduced [STA130F24_CourseProject.ipynb](https://github.com/pointOfive/stat130chat130/blob/main/CP/STA130F24_CourseProject.ipynb), and the [available variables](https://drive.google.com/file/d/1ISVymGn-WR1lcRs4psIym2N3or5onNBi/view). \n",
    "- Please do not download the [data](https://drive.google.com/file/d/1mbUQlMTrNYA7Ly5eImVRBn16Ehy9Lggo/view) accessible at the bottom of the [CSCS](https://casch.org/cscs) webpage (or the course github repo) multiple times.\n",
    "    \n",
    "\n",
    "> ### NEW DEVELOPMENT<br>New Abilities Achieved and New Levels Unlocked!!!    \n",
    "> \n",
    "> And with that, ALL LEVELS unlocked! \n",
    ">\n",
    "> CONGRATS, YOU LEGENDS! 🎉\n",
    ">\n",
    "> You’ve battled through the wild jungles of deadlines, defeated the mighty Homework Beasts, and climbed the towering Mount Procrastination. And guess what? YOU MADE IT TO THE TOP! 🏔️\n",
    "> \n",
    "> Take a bow, grab a treat, and enjoy the sweet, sweet taste of freedom(**just for now , because you still have to finish the project! But you are almost done!**). You’ve earned it. Now go out there and celebrate like the absolute rockstars you are! 🌟💪\n",
    ">\n",
    "\n",
    "    \n",
    "### Current Course Project Capability Level    \n",
    "    \n",
    "I mean, the **course project** is basically, like, essentially now.\n",
    "    \n",
    "- Will you be doing any **classification decision trees** stuff for the course project?\n",
    "    - You could consider making some [partial dependency plots](https://scikit-learn.org/stable/modules/partial_dependence.html) if so...\n",
    "    - those might provide an interesting analysis in addition to **tree structure** visualizations, **confusion matrices**, **feature importances**. and the standard \"in-sample versus out-of-sample\" **train-test validation** analysis that would be expected in a **machine learning context**\n",
    "    \n",
    "- You could see if there are any interesting columns that might make for a potentially interesting **classification decision tree** analysis\n",
    "    - You wouldn't have to though...\n",
    "    - But if you did you'd want to be able to articulate and explain why what you're doing with **classification decision trees** is appropriate and enlightening\n",
    "\n",
    "- Anyway, I guess that just leaves reviewing all the statistical techniques covered in STA130, and considering integrating them holistically into your project!\n",
    "    \n",
    "</details>        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524759d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
